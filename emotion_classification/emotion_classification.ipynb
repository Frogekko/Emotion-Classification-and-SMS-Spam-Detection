{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32bd8933-f9ce-4f12-89c9-6f0d6a2cfad4",
   "metadata": {},
   "source": [
    "# 1 - Imports and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1890d64-3092-4077-9f36-c3f830e2ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c182e0ea-14c7-4376-aa5c-e8383d6a0edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 211225 entries, 0 to 211224\n",
      "Data columns (total 37 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   text                  211225 non-null  object \n",
      " 1   id                    211225 non-null  object \n",
      " 2   author                211225 non-null  object \n",
      " 3   subreddit             211225 non-null  object \n",
      " 4   link_id               211225 non-null  object \n",
      " 5   parent_id             211225 non-null  object \n",
      " 6   created_utc           211225 non-null  float64\n",
      " 7   rater_id              211225 non-null  int64  \n",
      " 8   example_very_unclear  211225 non-null  bool   \n",
      " 9   admiration            211225 non-null  int64  \n",
      " 10  amusement             211225 non-null  int64  \n",
      " 11  anger                 211225 non-null  int64  \n",
      " 12  annoyance             211225 non-null  int64  \n",
      " 13  approval              211225 non-null  int64  \n",
      " 14  caring                211225 non-null  int64  \n",
      " 15  confusion             211225 non-null  int64  \n",
      " 16  curiosity             211225 non-null  int64  \n",
      " 17  desire                211225 non-null  int64  \n",
      " 18  disappointment        211225 non-null  int64  \n",
      " 19  disapproval           211225 non-null  int64  \n",
      " 20  disgust               211225 non-null  int64  \n",
      " 21  embarrassment         211225 non-null  int64  \n",
      " 22  excitement            211225 non-null  int64  \n",
      " 23  fear                  211225 non-null  int64  \n",
      " 24  gratitude             211225 non-null  int64  \n",
      " 25  grief                 211225 non-null  int64  \n",
      " 26  joy                   211225 non-null  int64  \n",
      " 27  love                  211225 non-null  int64  \n",
      " 28  nervousness           211225 non-null  int64  \n",
      " 29  optimism              211225 non-null  int64  \n",
      " 30  pride                 211225 non-null  int64  \n",
      " 31  realization           211225 non-null  int64  \n",
      " 32  relief                211225 non-null  int64  \n",
      " 33  remorse               211225 non-null  int64  \n",
      " 34  sadness               211225 non-null  int64  \n",
      " 35  surprise              211225 non-null  int64  \n",
      " 36  neutral               211225 non-null  int64  \n",
      "dtypes: bool(1), float64(1), int64(29), object(6)\n",
      "memory usage: 58.2+ MB\n",
      "\n",
      "--- Data Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>t3_ajis4z</td>\n",
       "      <td>t1_eew18eq</td>\n",
       "      <td>1.548381e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>eemcysk</td>\n",
       "      <td>TheGreen888</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>1.548084e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>t3_abru74</td>\n",
       "      <td>t1_ed2m7g7</td>\n",
       "      <td>1.546428e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>1.547965e+09</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>t3_ackt2f</td>\n",
       "      <td>t1_eda65q2</td>\n",
       "      <td>1.546669e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>ee6pagw</td>\n",
       "      <td>Senshado</td>\n",
       "      <td>heroesofthestorm</td>\n",
       "      <td>t3_agjf24</td>\n",
       "      <td>t3_agjf24</td>\n",
       "      <td>1.547634e+09</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when you’ve imported about a gazillion of...</td>\n",
       "      <td>ef28nod</td>\n",
       "      <td>5inchloser</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>t3_ak26t3</td>\n",
       "      <td>t3_ak26t3</td>\n",
       "      <td>1.548553e+09</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>ee8hse1</td>\n",
       "      <td>springt1me</td>\n",
       "      <td>shittyfoodporn</td>\n",
       "      <td>t3_agrnqb</td>\n",
       "      <td>t3_agrnqb</td>\n",
       "      <td>1.547684e+09</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here...</td>\n",
       "      <td>edrhoxh</td>\n",
       "      <td>enamedata</td>\n",
       "      <td>medicine</td>\n",
       "      <td>t3_aejqzd</td>\n",
       "      <td>t1_edrgdtx</td>\n",
       "      <td>1.547169e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211224</th>\n",
       "      <td>Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...</td>\n",
       "      <td>edze9g4</td>\n",
       "      <td>HelperBot_</td>\n",
       "      <td>MorbidReality</td>\n",
       "      <td>t3_afhw30</td>\n",
       "      <td>t1_edze91s</td>\n",
       "      <td>1.547397e+09</td>\n",
       "      <td>61</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211225 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       id  \\\n",
       "0                                         That game hurt.  eew5j0j   \n",
       "1        >sexuality shouldn’t be a grouping category I...  eemcysk   \n",
       "2          You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "3                                      Man I love reddit.  eeibobj   \n",
       "4       [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "...                                                   ...      ...   \n",
       "211220                             Everyone likes [NAME].  ee6pagw   \n",
       "211221  Well when you’ve imported about a gazillion of...  ef28nod   \n",
       "211222                                 That looks amazing  ee8hse1   \n",
       "211223  The FDA has plenty to criticize. But like here...  edrhoxh   \n",
       "211224  Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...  edze9g4   \n",
       "\n",
       "                     author            subreddit    link_id   parent_id  \\\n",
       "0                     Brdd9                  nrl  t3_ajis4z  t1_eew18eq   \n",
       "1               TheGreen888     unpopularopinion  t3_ai4q37   t3_ai4q37   \n",
       "2                  Labalool          confessions  t3_abru74  t1_ed2m7g7   \n",
       "3             MrsRobertshaw             facepalm  t3_ahulml   t3_ahulml   \n",
       "4       American_Fascist713  starwarsspeculation  t3_ackt2f  t1_eda65q2   \n",
       "...                     ...                  ...        ...         ...   \n",
       "211220             Senshado     heroesofthestorm  t3_agjf24   t3_agjf24   \n",
       "211221           5inchloser          nottheonion  t3_ak26t3   t3_ak26t3   \n",
       "211222           springt1me       shittyfoodporn  t3_agrnqb   t3_agrnqb   \n",
       "211223            enamedata             medicine  t3_aejqzd  t1_edrgdtx   \n",
       "211224           HelperBot_        MorbidReality  t3_afhw30  t1_edze91s   \n",
       "\n",
       "         created_utc  rater_id  example_very_unclear  admiration  ...  love  \\\n",
       "0       1.548381e+09         1                 False           0  ...     0   \n",
       "1       1.548084e+09        37                  True           0  ...     0   \n",
       "2       1.546428e+09        37                 False           0  ...     0   \n",
       "3       1.547965e+09        18                 False           0  ...     1   \n",
       "4       1.546669e+09         2                 False           0  ...     0   \n",
       "...              ...       ...                   ...         ...  ...   ...   \n",
       "211220  1.547634e+09        16                 False           0  ...     1   \n",
       "211221  1.548553e+09        15                 False           0  ...     0   \n",
       "211222  1.547684e+09        70                 False           1  ...     0   \n",
       "211223  1.547169e+09         4                 False           0  ...     0   \n",
       "211224  1.547397e+09        61                  True           0  ...     0   \n",
       "\n",
       "        nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
       "0                 0         0      0            0       0        0        1   \n",
       "1                 0         0      0            0       0        0        0   \n",
       "2                 0         0      0            0       0        0        0   \n",
       "3                 0         0      0            0       0        0        0   \n",
       "4                 0         0      0            0       0        0        0   \n",
       "...             ...       ...    ...          ...     ...      ...      ...   \n",
       "211220            0         0      0            0       0        0        0   \n",
       "211221            0         0      0            0       0        0        0   \n",
       "211222            0         0      0            0       0        0        0   \n",
       "211223            0         0      0            0       0        0        0   \n",
       "211224            0         0      0            0       0        0        0   \n",
       "\n",
       "        surprise  neutral  \n",
       "0              0        0  \n",
       "1              0        0  \n",
       "2              0        1  \n",
       "3              0        0  \n",
       "4              0        1  \n",
       "...          ...      ...  \n",
       "211220         0        0  \n",
       "211221         0        0  \n",
       "211222         0        0  \n",
       "211223         0        0  \n",
       "211224         0        0  \n",
       "\n",
       "[211225 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "try:\n",
    "    df = pd.read_csv('goemotions.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: goemotions.csv not found.\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\n--- Data Info ---\")\n",
    "df.info() # Found no missing values\n",
    "\n",
    "print(\"\\n--- Data Set ---\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d9faa-5692-487d-bc9e-23426f485007",
   "metadata": {},
   "source": [
    "# 2 - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8798fca-36b9-46c0-aa4c-3c676d72d4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Label Distribution ---\n",
      "                       Emotion  Count  Percentage\n",
      "admiration          admiration  17131    8.110309\n",
      "amusement            amusement   9245    4.376849\n",
      "anger                    anger   8084    3.827198\n",
      "annoyance            annoyance  13618    6.447154\n",
      "approval              approval  17620    8.341816\n",
      "caring                  caring   5999    2.840099\n",
      "confusion            confusion   7359    3.483963\n",
      "curiosity            curiosity   9692    4.588472\n",
      "desire                  desire   3817    1.807078\n",
      "disappointment  disappointment   8469    4.009469\n",
      "disapproval        disapproval  11424    5.408451\n",
      "disgust                disgust   5301    2.509646\n",
      "embarrassment    embarrassment   2476    1.172210\n",
      "excitement          excitement   5629    2.664931\n",
      "fear                      fear   3197    1.513552\n",
      "gratitude            gratitude  11625    5.503610\n",
      "grief                    grief    673    0.318618\n",
      "joy                        joy   7983    3.779382\n",
      "love                      love   8191    3.877855\n",
      "nervousness        nervousness   1810    0.856906\n",
      "optimism              optimism   8715    4.125932\n",
      "pride                    pride   1302    0.616404\n",
      "realization        realization   8785    4.159072\n",
      "relief                  relief   1289    0.610250\n",
      "remorse                remorse   2525    1.195408\n",
      "sadness                sadness   6758    3.199432\n",
      "surprise              surprise   5514    2.610486\n",
      "neutral                neutral  55298   26.179666\n",
      "\n",
      "--- Label Statistics ---\n",
      "Average number of labels per sample: 1.18\n",
      "Min labels per sample: 0\n",
      "Max labels per sample: 12\n"
     ]
    }
   ],
   "source": [
    "# Using the full dataset (211,225 samples)\n",
    "# Calculate label distribution\n",
    "emotion_labels = df.columns[9:37].tolist()  # Emotion columns (admiration to neutral)\n",
    "label_counts = df.iloc[:, 9:37].sum()  # Sum each emotion column to get frequency\n",
    "label_dist = pd.DataFrame({\n",
    "    'Emotion': emotion_labels,\n",
    "    'Count': label_counts,\n",
    "    'Percentage': (label_counts / len(df)) * 100\n",
    "})\n",
    "\n",
    "# Calculate average number of labels per sample\n",
    "labels_per_sample = df.iloc[:, 9:37].sum(axis=1)\n",
    "avg_labels_per_sample = labels_per_sample.mean()\n",
    "\n",
    "print(\"\\n--- Label Distribution ---\")\n",
    "print(label_dist)\n",
    "\n",
    "print(\"\\n--- Label Statistics ---\")\n",
    "print(f\"Average number of labels per sample: {avg_labels_per_sample:.2f}\")\n",
    "print(f\"Min labels per sample: {labels_per_sample.min()}\")\n",
    "print(f\"Max labels per sample: {labels_per_sample.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62023326-012a-49e5-b9db-8f717491514d",
   "metadata": {},
   "source": [
    "# 3 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e96e3acd-c5c5-4897-9c83-70cee0498028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Encoded Data Shape ---\n",
      "Input IDs: torch.Size([211225, 128])\n",
      "Attention Masks: torch.Size([211225, 128])\n",
      "Labels Shape: (211225, 28)\n"
     ]
    }
   ],
   "source": [
    "# Extract text and labels from the full dataset\n",
    "texts = df['text'].values\n",
    "labels = df.iloc[:, 9:].values  # Columns 9 to 36 are emotion labels\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the texts\n",
    "encoded_data = tokenizer(texts.tolist(), truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n",
    "\n",
    "print(\"\\n--- Encoded Data Shape ---\")\n",
    "print(f\"Input IDs: {encoded_data['input_ids'].shape}\")\n",
    "print(f\"Attention Masks: {encoded_data['attention_mask'].shape}\")\n",
    "print(f\"Labels Shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a62186-e9e8-4d61-a7e9-e5953e833329",
   "metadata": {},
   "source": [
    "# 4 - Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a54986-82a8-485c-9f9e-de6b40005ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Split Sizes ---\n",
      "Train Input IDs: torch.Size([168980, 128])\n",
      "Validation Input IDs: torch.Size([42245, 128])\n",
      "Train Labels: (168980, 28)\n",
      "Validation Labels: (42245, 28)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    encoded_data['input_ids'], labels, test_size=0.2, random_state=42\n",
    ")\n",
    "train_masks, val_masks = train_test_split(\n",
    "    encoded_data['attention_mask'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n--- Split Sizes ---\")\n",
    "print(f\"Train Input IDs: {train_texts.shape}\")\n",
    "print(f\"Validation Input IDs: {val_texts.shape}\")\n",
    "print(f\"Train Labels: {train_labels.shape}\")\n",
    "print(f\"Validation Labels: {val_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dcc5b-048e-4f37-babf-4f476d33e31e",
   "metadata": {},
   "source": [
    "# 5 - Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b725d8fe-5cee-4c07-a275-ca04afb9073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Loaded ---\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load BERT model with 28 emotion labels (excluding 'example_very_unclear')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=28)\n",
    "model.config.problem_type = \"multi_label_classification\"  # Set for multi-label task\n",
    "model.to(device)\n",
    "\n",
    "print(\"\\n--- Model Loaded ---\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff2d7d-2d03-4a96-a768-eb2920f36763",
   "metadata": {},
   "source": [
    "# 6 - Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52573f68-b042-4dd7-bb84-7b0c3f058c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Setup Complete ---\n",
      "Train Loader Size: 10562\n",
      "Validation Loader Size: 2641\n"
     ]
    }
   ],
   "source": [
    "# Convert to TensorDataset\n",
    "train_dataset = TensorDataset(\n",
    "    train_texts.clone().detach(), train_masks.clone().detach(), torch.tensor(train_labels)\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    val_texts.clone().detach(), val_masks.clone().detach(), torch.tensor(val_labels)\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "print(\"\\n--- Training Setup Complete ---\")\n",
    "print(f\"Train Loader Size: {len(train_loader)}\")\n",
    "print(f\"Validation Loader Size: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20fb979-684f-44e7-bec4-a5c06ea60bc5",
   "metadata": {},
   "source": [
    "# 7 - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "142308bb-7539-473b-83fe-896295bfa7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 10562/10562 [34:38<00:00,  5.08batch/s, loss=0.0955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Average Loss: 0.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 (Val): 100%|██████████| 2641/2641 [02:24<00:00, 18.26batch/s, loss=0.0818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as best_emotion_model.pt with validation loss: 0.1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 10562/10562 [31:30<00:00,  5.59batch/s, loss=0.0512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Average Loss: 0.1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 (Val): 100%|██████████| 2641/2641 [02:23<00:00, 18.44batch/s, loss=0.0713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as best_emotion_model.pt with validation loss: 0.1110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 10562/10562 [34:18<00:00,  5.13batch/s, loss=0.0396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Average Loss: 0.1032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 (Val): 100%|██████████| 2641/2641 [02:22<00:00, 18.54batch/s, loss=0.0757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 10562/10562 [42:02<00:00,  4.19batch/s, loss=0.097] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Average Loss: 0.0981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 (Val): 100%|██████████| 2641/2641 [03:08<00:00, 13.99batch/s, loss=0.0694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 2 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50:   6%|▋         | 675/10562 [02:27<36:05,  4.57batch/s, loss=0.0871]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m     16\u001b[0m     input_ids, attention_mask, labels \u001b[38;5;241m=\u001b[39m [b\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m---> 17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Ensure labels are float for multi-label\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, labels\u001b[38;5;241m=\u001b[39mlabels)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disable_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m prior_skip_guard_eval_unsafe \u001b[38;5;241m=\u001b[39m set_skip_guard_eval_unsafe(\n\u001b[0;32m    742\u001b[0m     _is_skip_guard_eval_unsafe_stance()\n\u001b[0;32m    743\u001b[0m )\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:975\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_to_none:\n\u001b[1;32m--> 975\u001b[0m         p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set number of epochs and early stopping parameters\n",
    "epochs = 50\n",
    "patience = 5  # Number of epochs with no improvement before early stopping\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "save_path = 'best_emotion_model.pt'\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Add progress bar for batches in this epoch\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar:\n",
    "        for batch in pbar:\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            labels = labels.float()  # Ensure labels are float for multi-label\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_postfix({'loss': loss.item()})  # Show current batch loss\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Validation and early stopping\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{epochs} (Val)\", unit=\"batch\") as pbar_val:\n",
    "            for batch in pbar_val:\n",
    "                input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "                labels = labels.float()  # Ensure labels are float for multi-label\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)  # Pass labels\n",
    "                val_loss = outputs.loss\n",
    "                total_val_loss += val_loss.item()\n",
    "                pbar_val.set_postfix({'loss': val_loss.item()})\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the model\n",
    "        try:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved as {save_path} with validation loss: {best_val_loss:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model: {e}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement in validation loss for {epochs_no_improve} epoch(s).\")\n",
    "    \n",
    "    # Check if early stopping is triggered\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break\n",
    "\n",
    "print(\"\\n--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97358f0b-edb1-496f-b65d-f7196edded0c",
   "metadata": {},
   "source": [
    "# 8 - Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45239eba-b6c7-4685-9154-f6a9f81d3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.sigmoid(outputs.logits).cpu().numpy() > 0.5\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "print(\"\\n--- Evaluation Results ---\")\n",
    "print(f\"F1 Score (Micro): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3b48cf-a5ea-4d5f-a381-d44dbdc65a0a",
   "metadata": {},
   "source": [
    "# 9 - Save and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983e460-16af-426d-a1ff-434b0c8731ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained('emotion_model')\n",
    "tokenizer.save_pretrained('emotion_model')\n",
    "\n",
    "# Test with a sample text\n",
    "sample_text = \"I am so excited to see my friends!\"\n",
    "inputs = tokenizer(sample_text, truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    preds = torch.sigmoid(outputs.logits).cpu().numpy()[0] > 0.5\n",
    "\n",
    "emotion_labels = df.columns[9:37].tolist()  # Get emotion column names\n",
    "predicted_emotions = [emotion_labels[i] for i, pred in enumerate(preds) if pred]\n",
    "print(\"\\n--- Sample Prediction ---\")\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Predicted Emotions: {predicted_emotions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842bd934-696a-44c8-92db-65ab690c0959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
