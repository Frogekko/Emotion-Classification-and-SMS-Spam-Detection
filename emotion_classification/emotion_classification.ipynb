{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32bd8933-f9ce-4f12-89c9-6f0d6a2cfad4",
   "metadata": {},
   "source": [
    "# 1 - Imports and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1890d64-3092-4077-9f36-c3f830e2ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c182e0ea-14c7-4376-aa5c-e8383d6a0edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 211225 entries, 0 to 211224\n",
      "Data columns (total 37 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   text                  211225 non-null  object \n",
      " 1   id                    211225 non-null  object \n",
      " 2   author                211225 non-null  object \n",
      " 3   subreddit             211225 non-null  object \n",
      " 4   link_id               211225 non-null  object \n",
      " 5   parent_id             211225 non-null  object \n",
      " 6   created_utc           211225 non-null  float64\n",
      " 7   rater_id              211225 non-null  int64  \n",
      " 8   example_very_unclear  211225 non-null  bool   \n",
      " 9   admiration            211225 non-null  int64  \n",
      " 10  amusement             211225 non-null  int64  \n",
      " 11  anger                 211225 non-null  int64  \n",
      " 12  annoyance             211225 non-null  int64  \n",
      " 13  approval              211225 non-null  int64  \n",
      " 14  caring                211225 non-null  int64  \n",
      " 15  confusion             211225 non-null  int64  \n",
      " 16  curiosity             211225 non-null  int64  \n",
      " 17  desire                211225 non-null  int64  \n",
      " 18  disappointment        211225 non-null  int64  \n",
      " 19  disapproval           211225 non-null  int64  \n",
      " 20  disgust               211225 non-null  int64  \n",
      " 21  embarrassment         211225 non-null  int64  \n",
      " 22  excitement            211225 non-null  int64  \n",
      " 23  fear                  211225 non-null  int64  \n",
      " 24  gratitude             211225 non-null  int64  \n",
      " 25  grief                 211225 non-null  int64  \n",
      " 26  joy                   211225 non-null  int64  \n",
      " 27  love                  211225 non-null  int64  \n",
      " 28  nervousness           211225 non-null  int64  \n",
      " 29  optimism              211225 non-null  int64  \n",
      " 30  pride                 211225 non-null  int64  \n",
      " 31  realization           211225 non-null  int64  \n",
      " 32  relief                211225 non-null  int64  \n",
      " 33  remorse               211225 non-null  int64  \n",
      " 34  sadness               211225 non-null  int64  \n",
      " 35  surprise              211225 non-null  int64  \n",
      " 36  neutral               211225 non-null  int64  \n",
      "dtypes: bool(1), float64(1), int64(29), object(6)\n",
      "memory usage: 58.2+ MB\n",
      "\n",
      "--- Data Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>t3_ajis4z</td>\n",
       "      <td>t1_eew18eq</td>\n",
       "      <td>1.548381e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>eemcysk</td>\n",
       "      <td>TheGreen888</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>1.548084e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>t3_abru74</td>\n",
       "      <td>t1_ed2m7g7</td>\n",
       "      <td>1.546428e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>1.547965e+09</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>t3_ackt2f</td>\n",
       "      <td>t1_eda65q2</td>\n",
       "      <td>1.546669e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>ee6pagw</td>\n",
       "      <td>Senshado</td>\n",
       "      <td>heroesofthestorm</td>\n",
       "      <td>t3_agjf24</td>\n",
       "      <td>t3_agjf24</td>\n",
       "      <td>1.547634e+09</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when you’ve imported about a gazillion of...</td>\n",
       "      <td>ef28nod</td>\n",
       "      <td>5inchloser</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>t3_ak26t3</td>\n",
       "      <td>t3_ak26t3</td>\n",
       "      <td>1.548553e+09</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>ee8hse1</td>\n",
       "      <td>springt1me</td>\n",
       "      <td>shittyfoodporn</td>\n",
       "      <td>t3_agrnqb</td>\n",
       "      <td>t3_agrnqb</td>\n",
       "      <td>1.547684e+09</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here...</td>\n",
       "      <td>edrhoxh</td>\n",
       "      <td>enamedata</td>\n",
       "      <td>medicine</td>\n",
       "      <td>t3_aejqzd</td>\n",
       "      <td>t1_edrgdtx</td>\n",
       "      <td>1.547169e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211224</th>\n",
       "      <td>Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...</td>\n",
       "      <td>edze9g4</td>\n",
       "      <td>HelperBot_</td>\n",
       "      <td>MorbidReality</td>\n",
       "      <td>t3_afhw30</td>\n",
       "      <td>t1_edze91s</td>\n",
       "      <td>1.547397e+09</td>\n",
       "      <td>61</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211225 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       id  \\\n",
       "0                                         That game hurt.  eew5j0j   \n",
       "1        >sexuality shouldn’t be a grouping category I...  eemcysk   \n",
       "2          You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "3                                      Man I love reddit.  eeibobj   \n",
       "4       [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "...                                                   ...      ...   \n",
       "211220                             Everyone likes [NAME].  ee6pagw   \n",
       "211221  Well when you’ve imported about a gazillion of...  ef28nod   \n",
       "211222                                 That looks amazing  ee8hse1   \n",
       "211223  The FDA has plenty to criticize. But like here...  edrhoxh   \n",
       "211224  Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...  edze9g4   \n",
       "\n",
       "                     author            subreddit    link_id   parent_id  \\\n",
       "0                     Brdd9                  nrl  t3_ajis4z  t1_eew18eq   \n",
       "1               TheGreen888     unpopularopinion  t3_ai4q37   t3_ai4q37   \n",
       "2                  Labalool          confessions  t3_abru74  t1_ed2m7g7   \n",
       "3             MrsRobertshaw             facepalm  t3_ahulml   t3_ahulml   \n",
       "4       American_Fascist713  starwarsspeculation  t3_ackt2f  t1_eda65q2   \n",
       "...                     ...                  ...        ...         ...   \n",
       "211220             Senshado     heroesofthestorm  t3_agjf24   t3_agjf24   \n",
       "211221           5inchloser          nottheonion  t3_ak26t3   t3_ak26t3   \n",
       "211222           springt1me       shittyfoodporn  t3_agrnqb   t3_agrnqb   \n",
       "211223            enamedata             medicine  t3_aejqzd  t1_edrgdtx   \n",
       "211224           HelperBot_        MorbidReality  t3_afhw30  t1_edze91s   \n",
       "\n",
       "         created_utc  rater_id  example_very_unclear  admiration  ...  love  \\\n",
       "0       1.548381e+09         1                 False           0  ...     0   \n",
       "1       1.548084e+09        37                  True           0  ...     0   \n",
       "2       1.546428e+09        37                 False           0  ...     0   \n",
       "3       1.547965e+09        18                 False           0  ...     1   \n",
       "4       1.546669e+09         2                 False           0  ...     0   \n",
       "...              ...       ...                   ...         ...  ...   ...   \n",
       "211220  1.547634e+09        16                 False           0  ...     1   \n",
       "211221  1.548553e+09        15                 False           0  ...     0   \n",
       "211222  1.547684e+09        70                 False           1  ...     0   \n",
       "211223  1.547169e+09         4                 False           0  ...     0   \n",
       "211224  1.547397e+09        61                  True           0  ...     0   \n",
       "\n",
       "        nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
       "0                 0         0      0            0       0        0        1   \n",
       "1                 0         0      0            0       0        0        0   \n",
       "2                 0         0      0            0       0        0        0   \n",
       "3                 0         0      0            0       0        0        0   \n",
       "4                 0         0      0            0       0        0        0   \n",
       "...             ...       ...    ...          ...     ...      ...      ...   \n",
       "211220            0         0      0            0       0        0        0   \n",
       "211221            0         0      0            0       0        0        0   \n",
       "211222            0         0      0            0       0        0        0   \n",
       "211223            0         0      0            0       0        0        0   \n",
       "211224            0         0      0            0       0        0        0   \n",
       "\n",
       "        surprise  neutral  \n",
       "0              0        0  \n",
       "1              0        0  \n",
       "2              0        1  \n",
       "3              0        0  \n",
       "4              0        1  \n",
       "...          ...      ...  \n",
       "211220         0        0  \n",
       "211221         0        0  \n",
       "211222         0        0  \n",
       "211223         0        0  \n",
       "211224         0        0  \n",
       "\n",
       "[211225 rows x 37 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "try:\n",
    "    df = pd.read_csv('goemotions.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: goemotions.csv not found.\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\n--- Data Info ---\")\n",
    "df.info() # Found no missing values\n",
    "\n",
    "print(\"\\n--- Data Set ---\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d9faa-5692-487d-bc9e-23426f485007",
   "metadata": {},
   "source": [
    "# 2 - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8798fca-36b9-46c0-aa4c-3c676d72d4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Label Distribution ---\n",
      "           Emotion  Count  Percentage\n",
      "0       admiration  17131    8.110309\n",
      "1        amusement   9245    4.376849\n",
      "2            anger   8084    3.827198\n",
      "3        annoyance  13618    6.447154\n",
      "4         approval  17620    8.341816\n",
      "5           caring   5999    2.840099\n",
      "6        confusion   7359    3.483963\n",
      "7        curiosity   9692    4.588472\n",
      "8           desire   3817    1.807078\n",
      "9   disappointment   8469    4.009469\n",
      "10     disapproval  11424    5.408451\n",
      "11         disgust   5301    2.509646\n",
      "12   embarrassment   2476    1.172210\n",
      "13      excitement   5629    2.664931\n",
      "14            fear   3197    1.513552\n",
      "15       gratitude  11625    5.503610\n",
      "16           grief    673    0.318618\n",
      "17             joy   7983    3.779382\n",
      "18            love   8191    3.877855\n",
      "19     nervousness   1810    0.856906\n",
      "20        optimism   8715    4.125932\n",
      "21           pride   1302    0.616404\n",
      "22     realization   8785    4.159072\n",
      "23          relief   1289    0.610250\n",
      "24         remorse   2525    1.195408\n",
      "25         sadness   6758    3.199432\n",
      "26        surprise   5514    2.610486\n",
      "27         neutral  55298   26.179666\n",
      "\n",
      "--- Label Statistics ---\n",
      "Average number of labels per sample: 1.18\n",
      "Min labels per sample: 0\n",
      "Max labels per sample: 12\n"
     ]
    }
   ],
   "source": [
    "# Using the full dataset (211,225 samples)\n",
    "# Calculate label distribution\n",
    "emotion_labels = df.columns[9:37].tolist()  # Emotion columns (admiration to neutral)\n",
    "label_counts = df.iloc[:, 9:37].sum().values  # Sum each emotion column to get frequency (NumPy array)\n",
    "label_dist = pd.DataFrame({\n",
    "    'Emotion': emotion_labels,\n",
    "    'Count': label_counts,\n",
    "    'Percentage': (label_counts / len(df)) * 100\n",
    "}) # Creates a dataframe to display label counts and percentages\n",
    "\n",
    "# Calculate average number of labels per sample\n",
    "labels_per_sample = df.iloc[:, 9:37].sum(axis=1)\n",
    "avg_labels_per_sample = labels_per_sample.mean()\n",
    "\n",
    "print(\"\\n--- Label Distribution ---\")\n",
    "print(label_dist)\n",
    "\n",
    "print(\"\\n--- Label Statistics ---\")\n",
    "print(f\"Average number of labels per sample: {avg_labels_per_sample:.2f}\")\n",
    "print(f\"Min labels per sample: {labels_per_sample.min()}\")\n",
    "print(f\"Max labels per sample: {labels_per_sample.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62023326-012a-49e5-b9db-8f717491514d",
   "metadata": {},
   "source": [
    "# 3 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e96e3acd-c5c5-4897-9c83-70cee0498028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Token Length Distribution ---\n",
      "Total samples: 211225\n",
      "Maximum token length: 316\n",
      "Mean token length: 19.40\n",
      "Median token length: 19.00\n",
      "95th percentile: 34.00\n",
      "99th percentile: 38.00\n",
      "Samples truncated at max_length=128: 3 (0.00%)\n",
      "\n",
      "--- Encoded Data Shape ---\n",
      "Input IDs: torch.Size([211225, 128])\n",
      "Attention Masks: torch.Size([211225, 128])\n",
      "Labels Shape: (211225, 28)\n"
     ]
    }
   ],
   "source": [
    "# Extract text and labels from the full dataset\n",
    "texts = df['text'].values # Converts to NumPy array for later use\n",
    "labels = df.iloc[:, 9:37].values # Columns 9 to 36 are emotion labels\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Calculate token lengths for all texts\n",
    "token_lengths = [len(tokenizer.encode(text, add_special_tokens=True)) for text in df['text']]\n",
    "\n",
    "# Compute statistics\n",
    "max_length = max(token_lengths)\n",
    "median_length = np.median(token_lengths)\n",
    "mean_length = np.mean(token_lengths)\n",
    "percentile_95 = np.percentile(token_lengths, 95)\n",
    "percentile_99 = np.percentile(token_lengths, 99)\n",
    "truncated_count = sum(1 for length in token_lengths if length > 128)\n",
    "\n",
    "# Print results\n",
    "print(\"\\n--- Token Length Distribution ---\")\n",
    "print(f\"Maximum token length: {max_length}\")\n",
    "print(f\"Mean token length: {mean_length:.2f}\")\n",
    "print(f\"Median token length: {median_length:.2f}\")\n",
    "print(f\"95th percentile: {percentile_95:.2f}\")\n",
    "print(f\"99th percentile: {percentile_99:.2f}\")\n",
    "print(f\"Samples truncated at max_length=128: {truncated_count} ({truncated_count/len(token_lengths)*100:.2f}%)\")\n",
    "\n",
    "# Tokenize the texts\n",
    "encoded_data = tokenizer(texts.tolist(), truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n",
    "\n",
    "print(\"\\n--- Encoded Data Shape ---\")\n",
    "print(f\"Input IDs: {encoded_data['input_ids'].shape}\")\n",
    "print(f\"Attention Masks: {encoded_data['attention_mask'].shape}\")\n",
    "print(f\"Labels Shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a62186-e9e8-4d61-a7e9-e5953e833329",
   "metadata": {},
   "source": [
    "# 4 - Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a54986-82a8-485c-9f9e-de6b40005ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Split Sizes ---\n",
      "Train Input IDs: torch.Size([147857, 128])\n",
      "Validation Input IDs: torch.Size([31684, 128])\n",
      "Test Input IDs: torch.Size([31684, 128])\n",
      "Train Labels: (147857, 28)\n",
      "Validation Labels: (31684, 28)\n",
      "Test Labels: (31684, 28)\n"
     ]
    }
   ],
   "source": [
    "# Split into train, validation, and test sets\n",
    "train_texts, temp_texts, train_masks, temp_masks, train_labels, temp_labels = train_test_split(\n",
    "    encoded_data['input_ids'], encoded_data['attention_mask'], labels, \n",
    "    test_size=0.3, random_state=42  # 70% train, 30% temp (val + test)\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_masks, test_masks, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_masks, temp_labels, \n",
    "    test_size=0.5, random_state=42  # Split 30% into 15% val and 15% test\n",
    ")\n",
    "\n",
    "print(\"\\n--- Split Sizes ---\")\n",
    "print(f\"Train Input IDs: {train_texts.shape}\")\n",
    "print(f\"Validation Input IDs: {val_texts.shape}\")\n",
    "print(f\"Test Input IDs: {test_texts.shape}\")\n",
    "print(f\"Train Labels: {train_labels.shape}\")\n",
    "print(f\"Validation Labels: {val_labels.shape}\")\n",
    "print(f\"Test Labels: {test_labels.shape}\")\n",
    "\n",
    "# Create TensorDatasets for PyTorch DataLoader (combines inputs, masks and labels into a dataset object)\n",
    "train_dataset = TensorDataset(train_texts, train_masks, torch.tensor(train_labels))\n",
    "val_dataset = TensorDataset(val_texts, val_masks, torch.tensor(val_labels))\n",
    "test_dataset = TensorDataset(test_texts, test_masks, torch.tensor(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dcc5b-048e-4f37-babf-4f476d33e31e",
   "metadata": {},
   "source": [
    "# 5 - Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b725d8fe-5cee-4c07-a275-ca04afb9073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Loaded ---\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device to CUDA if available as it massively speeds up training times\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load BERT model with 28 emotion labels (excluding 'example_very_unclear')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=28)\n",
    "# This ensures the model uses a sigmoid activation on the outputs and an appropriate loss function (like BCEWithLogitsLoss)\n",
    "model.config.problem_type = \"multi_label_classification\"  # Set for multi-label task\n",
    "model.to(device)\n",
    "\n",
    "print(\"\\n--- Model Loaded ---\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff2d7d-2d03-4a96-a768-eb2920f36763",
   "metadata": {},
   "source": [
    "# 6 - Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52573f68-b042-4dd7-bb84-7b0c3f058c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Setup Complete ---\n",
      "Train Loader Size: 4621\n",
      "Validation Loader Size: 991\n",
      "Test Loader Size: 991\n"
     ]
    }
   ],
   "source": [
    "# DataLoaders (shuffle is set to 'True' to randomize data order for better generalization)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Set up optimizer, AdamW is a common optimizer for transformer models\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Calculate class weights based on label frequencies to adress class imbalance, gives higher weight to less frequent classes\n",
    "class_weights = 1.0 / torch.tensor(label_counts, dtype=torch.float).to(device)\n",
    "class_weights = class_weights / class_weights.sum() * 28  # Normalize for 28 classes\n",
    "criterion = BCEWithLogitsLoss(pos_weight=class_weights) # 'pos_weight' applies the calculated class weights\n",
    "\n",
    "print(\"\\n--- Training Setup Complete ---\")\n",
    "print(f\"Train Loader Size: {len(train_loader)}\")\n",
    "print(f\"Validation Loader Size: {len(val_loader)}\")\n",
    "print(f\"Test Loader Size: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20fb979-684f-44e7-bec4-a5c06ea60bc5",
   "metadata": {},
   "source": [
    "# 7 - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142308bb-7539-473b-83fe-896295bfa7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for training\n",
    "epochs = 50\n",
    "patience = 5 # Number of epochs to wait before early stopping\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "save_path = 'best_emotion_model.pt'\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train() # Set model to training mode\n",
    "    total_train_loss = 0\n",
    "    # Use a progress bar over the training batches\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar: # Progress bar\n",
    "        for batch in pbar:\n",
    "            batch = [b.to(device) for b in batch] # Move batch to device\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            labels = labels.float() # Ensure labels are float for multilabel\n",
    "            optimizer.zero_grad() # Clears the previous gradients\n",
    "            # Forward pass: compute model outputs and loss\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_train_loss += loss.item() # Accumulate loss\n",
    "            loss.backward() # Backward pass: compute gradients\n",
    "            optimizer.step() # Update model parameters\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Average Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval() # Set model to evaluate mode\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad(): # Disable gradient calculations for validation\n",
    "        with tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{epochs} (Val)\", unit=\"batch\") as pbar:\n",
    "            for batch in pbar:\n",
    "                batch = [b.to(device) for b in batch]\n",
    "                input_ids, attention_mask, labels = batch\n",
    "                labels = labels.float()\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                total_val_loss += outputs.loss.item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    # Early stopping and saving logic\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        try:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved as {save_path} with validation loss: {best_val_loss:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model: {e}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement in validation loss for {epochs_no_improve} epoch(s).\")\n",
    "    \n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break # Exit training loop\n",
    "\n",
    "print(\"\\n--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97358f0b-edb1-496f-b65d-f7196edded0c",
   "metadata": {},
   "source": [
    "# 8 - Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45239eba-b6c7-4685-9154-f6a9f81d3e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Validation: 100%|██████████| 991/991 [01:34<00:00, 10.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Thresholds per Emotion (Validation): {'admiration': np.float64(0.30000000000000004), 'amusement': np.float64(0.30000000000000004), 'anger': np.float64(0.2), 'annoyance': np.float64(0.2), 'approval': np.float64(0.2), 'caring': np.float64(0.2), 'confusion': np.float64(0.2), 'curiosity': np.float64(0.2), 'desire': np.float64(0.2), 'disappointment': np.float64(0.2), 'disapproval': np.float64(0.2), 'disgust': np.float64(0.2), 'embarrassment': np.float64(0.2), 'excitement': np.float64(0.1), 'fear': np.float64(0.2), 'gratitude': np.float64(0.6), 'grief': np.float64(0.1), 'joy': np.float64(0.30000000000000004), 'love': np.float64(0.30000000000000004), 'nervousness': np.float64(0.1), 'optimism': np.float64(0.30000000000000004), 'pride': np.float64(0.1), 'realization': np.float64(0.1), 'relief': np.float64(0.1), 'remorse': np.float64(0.2), 'sadness': np.float64(0.30000000000000004), 'surprise': np.float64(0.2), 'neutral': np.float64(0.2)}\n",
      "\n",
      "--- Validation Results ---\n",
      "Micro F1: 0.4402\n",
      "Macro F1: 0.3696\n",
      "Accuracy: 0.2169\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.50      0.68      0.57      2636\n",
      "     amusement       0.55      0.75      0.63      1386\n",
      "         anger       0.33      0.49      0.39      1174\n",
      "     annoyance       0.25      0.40      0.31      2070\n",
      "      approval       0.27      0.33      0.30      2600\n",
      "        caring       0.26      0.45      0.33       869\n",
      "     confusion       0.27      0.43      0.33      1090\n",
      "     curiosity       0.33      0.72      0.45      1413\n",
      "        desire       0.36      0.35      0.35       561\n",
      "disappointment       0.23      0.28      0.25      1244\n",
      "   disapproval       0.25      0.43      0.32      1710\n",
      "       disgust       0.33      0.33      0.33       854\n",
      " embarrassment       0.40      0.23      0.29       376\n",
      "    excitement       0.21      0.45      0.29       872\n",
      "          fear       0.42      0.46      0.44       458\n",
      "     gratitude       0.89      0.76      0.82      1755\n",
      "         grief       0.50      0.01      0.02        94\n",
      "           joy       0.44      0.39      0.41      1176\n",
      "          love       0.56      0.78      0.65      1203\n",
      "   nervousness       0.20      0.26      0.23       259\n",
      "      optimism       0.45      0.34      0.39      1375\n",
      "         pride       0.75      0.01      0.03       207\n",
      "   realization       0.15      0.32      0.20      1321\n",
      "        relief       0.14      0.14      0.14       210\n",
      "       remorse       0.42      0.61      0.49       380\n",
      "       sadness       0.39      0.42      0.40       955\n",
      "      surprise       0.39      0.46      0.42       779\n",
      "       neutral       0.45      0.70      0.55      8389\n",
      "\n",
      "     micro avg       0.38      0.53      0.44     37416\n",
      "     macro avg       0.38      0.43      0.37     37416\n",
      "  weighted avg       0.40      0.53      0.44     37416\n",
      "   samples avg       0.41      0.54      0.45     37416\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test: 100%|██████████| 991/991 [01:32<00:00, 10.66batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Results ---\n",
      "Micro F1: 0.4375\n",
      "Macro F1: 0.3666\n",
      "Accuracy: 0.2183\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.51      0.68      0.58      2587\n",
      "     amusement       0.53      0.74      0.62      1414\n",
      "         anger       0.34      0.48      0.40      1235\n",
      "     annoyance       0.25      0.40      0.30      2002\n",
      "      approval       0.26      0.32      0.29      2577\n",
      "        caring       0.26      0.45      0.33       863\n",
      "     confusion       0.27      0.42      0.33      1114\n",
      "     curiosity       0.33      0.70      0.45      1445\n",
      "        desire       0.34      0.33      0.33       596\n",
      "disappointment       0.21      0.26      0.23      1283\n",
      "   disapproval       0.26      0.44      0.33      1778\n",
      "       disgust       0.27      0.29      0.28       751\n",
      " embarrassment       0.41      0.26      0.31       372\n",
      "    excitement       0.21      0.45      0.28       830\n",
      "          fear       0.45      0.47      0.46       487\n",
      "     gratitude       0.88      0.74      0.80      1709\n",
      "         grief       0.00      0.00      0.00        88\n",
      "           joy       0.44      0.39      0.41      1200\n",
      "          love       0.55      0.76      0.64      1235\n",
      "   nervousness       0.18      0.23      0.20       294\n",
      "      optimism       0.45      0.39      0.42      1269\n",
      "         pride       0.50      0.02      0.03       195\n",
      "   realization       0.14      0.30      0.19      1272\n",
      "        relief       0.16      0.18      0.17       177\n",
      "       remorse       0.41      0.62      0.49       369\n",
      "       sadness       0.39      0.38      0.39      1013\n",
      "      surprise       0.41      0.43      0.42       831\n",
      "       neutral       0.45      0.70      0.55      8333\n",
      "\n",
      "     micro avg       0.38      0.52      0.44     37319\n",
      "     macro avg       0.35      0.42      0.37     37319\n",
      "  weighted avg       0.39      0.52      0.44     37319\n",
      "   samples avg       0.41      0.54      0.44     37319\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model saved during training\n",
    "model.load_state_dict(torch.load('best_emotion_model.pt'))  # Load the saved state_dict of the best-performing model\n",
    "model.eval()\n",
    "\n",
    "# Evaluation function with optimal threshold tuning\n",
    "def evaluate_model(loader, dataset_name=\"Validation\", thresholds=None):\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        for batch in tqdm(loader, desc=f\"Evaluating {dataset_name}\", unit=\"batch\"):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]  # Move batch to device\n",
    "            labels = labels.float()  # Ensure labels are float for compatibility\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.sigmoid(outputs.logits).cpu().numpy()  # Apply sigmoid to logits and convert to numpy\n",
    "            all_probs.append(probs)  # Store probabilities\n",
    "            all_labels.append(labels.cpu().numpy())  # Store true labels\n",
    "    all_probs = np.vstack(all_probs)  # Stack probabilities into a single array\n",
    "    all_labels = np.vstack(all_labels)  # Stack labels into a single array\n",
    "    \n",
    "    # Tune thresholds if not provided\n",
    "    if thresholds is None:\n",
    "        thresholds = []\n",
    "        for i in range(all_probs.shape[1]):  # Iterate over each emotion class\n",
    "            best_f1 = 0\n",
    "            best_t = 0.5  # Default threshold\n",
    "            for t in np.arange(0.1, 0.9, 0.1):  # Test thresholds from 0.1 to 0.9\n",
    "                preds = all_probs[:, i] > t  # Apply threshold to predictions\n",
    "                f1 = f1_score(all_labels[:, i], preds)  # Compute F1 score\n",
    "                if f1 > best_f1:  # Update if better F1 score found\n",
    "                    best_f1 = f1\n",
    "                    best_t = t\n",
    "            thresholds.append(best_t)  # Store optimal threshold for this class\n",
    "        print(f\"\\nOptimal Thresholds per Emotion ({dataset_name}):\", dict(zip(emotion_labels, thresholds)))  # Display thresholds\n",
    "    \n",
    "    # Apply thresholds to get binary predictions\n",
    "    preds = np.zeros_like(all_probs)  # Initialize prediction array\n",
    "    for i in range(all_probs.shape[1]):  # Apply threshold for each class\n",
    "        preds[:, i] = all_probs[:, i] > thresholds[i]\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    micro_f1 = f1_score(all_labels, preds, average='micro')\n",
    "    macro_f1 = f1_score(all_labels, preds, average='macro')\n",
    "    accuracy = accuracy_score(all_labels, preds)\n",
    "    report = classification_report(all_labels, preds, target_names=emotion_labels, zero_division=0)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n--- {dataset_name} Results ---\")\n",
    "    print(f\"Micro F1: {micro_f1:.4f}\")\n",
    "    print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    return micro_f1, macro_f1, accuracy, report, thresholds\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "val_micro_f1, val_macro_f1, val_accuracy, val_report, optimal_thresholds = evaluate_model(val_loader, \"Validation\")  # Evaluate on validation set and get optimal thresholds\n",
    "test_micro_f1, test_macro_f1, test_accuracy, test_report, _ = evaluate_model(test_loader, \"Test\", optimal_thresholds)  # Evaluate on test set using validation thresholds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exam_prog",
   "language": "python",
   "name": "exam_prog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
